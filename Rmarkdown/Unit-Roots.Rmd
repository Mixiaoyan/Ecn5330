---
title: "Unit Roots"
author: "Tyler J. Brough"
date: "12/3/2016"
output: html_document
---

## Unit Roots

The basic random walk is:

$$
x_{t} = x_{t-1} + \varepsilon_{t}
$$
with $E_{t-1}[\varepsilon_{t}] = 0$.

Note the property: $E_{t}[x_{t+1}] = x_{t}$ (called the Martingale property)

## $\phantom{Page 2}$

Because of this property random walks are a popular model for asset prices.

_Notice_: the random walk is a special case of the $AR(1)$ model for which $\phi = 1$

$$
x_{t} = \phi x_{t-1} + \varepsilon_{t}
$$

Ex: $x_{0}$ - the initial value of the series is a real number denoting the starting value of the process. If $x_{t}$ is the log price of a stock then $x_{0}$ woudl be the log price of the stock at its initial public offering (IPO).

## $\phantom{Page 3}$

If $\varepsilon_{t}$ has a symmetric distribution (e.g. normal, student-t, etc) around zero, then conditional on $x_{t-1}$, $x_{t}$ has a 50-50 chance to go up or down, implying that $x_{t}$ would go up or down at random.

_NB_: this fits well the economics of the Efficient Markets Hypothesis (EMH). Early tests of the EMH were essentially tests for a random walk.

## $\phantom{Page 4}$

Within the $AR(1)$ framework $\phi = 1$, which does not satisfy the weak-stationarity assumption. A random walk is not weakly stationary, and we can it a unit-root nonstationary time series.

Under the random walk model of (log) stock prices the price is not predictable or mean-reverting.

We will take a small detour regarding forecasting to show this.

_Note_: notes on forecasting omitted for now. Will repost when completed. $\phantom{Comprising pages 5-19}$

## Simulating a Simple Random Walk

The following simple code simulates a Random Walk and plots it.

```{r message=FALSE, warning=FALSE}
library(xts)
begPrc <- 41.0
t <- seq(as.Date("2016-01-01"), as.Date("2016-12-2"), "days")
x = xts(begPrc + cumsum(rnorm(length(t))), order.by = t)
plot.xts(x, main = "Simulated Price")
```

## Random Walk with Drift $\phantom{Page 20}$ 

$$
x_{t} = \mu + x_{t-1} + \varepsilon_{t}
$$

where $\mu = E[x_{t} - x_{t-1}]$.

In finance (and macroeconomics) $\mu$ can be important. It is called the drift. 

## $\phantom{Page 21}$ 
  
To see this use recursive substitution:

$$
\begin{align}
x_{1} &= \mu + x_{0} + \varepsilon_{1} \\
x_{2} &= \mu + x_{1} + \varepsilon_{2} \\
      &= 2 \mu + x_{0} + \varepsilon_{2} + \varepsilon_{1} \\
\vdots &= \quad \vdots \\
x_{t} &= t \mu + x_{0} + \varepsilon_{t} + \varepsilon_{t-1} + \cdots + \varepsilon_{1}
\end{align}
$$

The last equation shows that ${x_{t}}$ consists of a time trend $t \mu$ and a pure random walk process
$\sum\limits_{i=1}^{t} \varepsilon_{i}$

$\phantom{---- Break between sets of notes --- below notes dated 02242011 ----}$

## $\phantom{Page 3}$

$$
var\left(\sum\limits_{i=1}^{t} \varepsilon_{i}\right) = t \sigma_{\varepsilon}^{2} 
$$

where $\sigma_{\varepsilon}^{2}$ is the variance of $\varepsilon_{t}$.

The conditional standard deviation of $x_{t}$ is $\sqrt{t} \sigma_{\varepsilon}^{2}$, which grows at a slower rate than
the conditional expectation of $x_{t}$. Therefore, if we graph $x_{t}$ against the time index $t$, we have a time trend
with slope $\mu$.

<br><br>

We can do this in R as follows (the dates are just needed to be able to use xts - they are randomly chosen):

<br>

```{r message=FALSE, warning=FALSE}
library(xts)
mu <- 0.08
begPrc <- 41.0
t <- seq(as.Date("2010-01-01"), length.out = 1000, by = 1)
x = xts(begPrc + cumsum(mu + rnorm(length(t))), order.by = t)
plot.xts(x, main = "Simulated Price with Drift")
```

## Differencing $\phantom{Page 7}$

A time series $x_{t}$ is said to be an $ARIMA(p,1,q)$ process of the change series:

$$
c_{t} = x_{t} - x_{t-1} = (1 - L)x_{t}
$$

follows a stationary and invertible $ARMA(p,q)$ process.

<br>

_Ex:_ in finance price series are commonly believed to be nonstationary, but the log return series $r_{t} = \log(p_{t})
- \log(p_{t-1})$ is stationary. Here the price series $\{p_{t}\}$ is unit-root nonstationary and hence can be treated as
an $ARIMA$ process.

<br>

## Testing for Unit Roots

__Q:__ Do economic variables such as GNP, employment, and interest rates tend to revert back to a long-run trend after a
shock, or do they follow random walks:

The question is important for (at least) two reasons:

1. If these variables follow random walks, a regression of one against another can lead to spurious results (more on
   this later). 
  * For example, suppose two series are generated by independent random walks, a regression of one against another can
	lead to spurious results. 
  * For example suppose two series are generated by independent random walks, 

$$
\begin{align}
x_{t} &= x_{t-1} + \varepsilon_{1,t} \\
y_{t} &= y_{t-1} + \varepsilon_{2,t} 
\end{align}
$$

  * With $E(\varepsilon_{1,t}, \varepsilon_{2,s}) = 0$ for all $t,s$
  * Now suppose we regress $y_{t}$ on $x_{t}$ by OLS

$$
y_{t} = \alpha + \beta x_{t} + u_{t}
$$

The assumptions underlying the CRLM are violated. In this case you tend to see "significant" $\beta$ coefficients more
often than the OLS formulas say you should. We will conduct a Monte Carlo study to demonstrate this in the next set of
notes.  

2. It affects our understanding of the economy and our ability to make forecasts.
  * If a variable such GNP follows a random walk, then the effects of a temporay shock (e.g. an increase in oil prices
	or an increase in government spending) will not dissapate after several years but will instead have permanent
	effects. 
  * If asset prices follow random walk processes they should not be forecastable.   

<br>

## $\phantom{Nelson & Plosser -  Page 12}$

Nelson & Plosser: <http://www.sciencedirect.com/science/article/pii/0304393282900125>

NP found evidence that GNP and other macro variables behave like random walks. This spurred a huge literature to
investigate whether or not economic and financial variables are random walks or are trend-reverting. Several of these
studies show that many economic time series do appear to be random walks or at least have random walk components.

## $\phantom{Page 13}$ 

Most of these studies use unit-root tests introduced by Dickey & Fuller (1979) JASA. 

<br>

Suppose, we believe that a variable $y_{t}$, which has been growing over time, can be described by the following
equation:

$$
y_{t} = \alpha \beta t + \rho y_{t-1} + \varepsilon_{t}
$$

One possibility is that $y_{t}$ has been growing because $y_{t}$ has a positivie time trend ($\beta > 0$) but would be
stationary after detrending (i.e. $\rho < 1$). 

<br>

In this case $y_{t}$ could be used in a regression and all of the results and tests of the CLRM would apply. 


## $\phantom{Page 14}$ 

Another possibility is that $y_{t}$ has been growing because it follows a random walk with a positive drift (i.e.
$\alpha > 0$, $\beta = 0$, and $\rho = 1$). In this case we would need to work with $\Delta y_{t}$ (change series).

<br>

Detrending would not make the series stationary, and the inclusion of $y_{t}$ in a regression would lead to spurious
results. 

<br>

One might think that the equation could be estimated by OLS and that the $t$-statistic on $\hat{\rho}$ could be used to
test $H_{0}: \rho = 1$. However, if the true value is indeed $1$ then OLS would lead to spurious results, which could
mean we could incorrectly reject the random walk hypothesis. 

## $\phantom{Page 15}$ 

Dickey & Fuller (DF) derived the distribution for the estimator $\hat{\rho}$ that holds when $\rho = 1$ and generated
statistics for an $F$-test of the random walk hypothesis, i.e. the hypothesis that $\beta = 0$ and $\rho = 1$. 

<br>

The DF test works as follows, supposing

$$
y_{t} = \alpha + \beta t + \rho y_{t-1} + \varepsilon_{t}
$$

First, using OLS run the (unrestricted) regression

$$
y_{t} - y_{t-1} = \Delta y_{t} = \alpha + \beta t + (\rho - 1) y_{t-1} 
$$

and then the restricted regression:

$$
y_{t} - y_{t-1} = \Delta y_{t} = \alpha
$$


## $\phantom{Page 16}$ 

Then calculate the $F$-ratio

$$
F = \frac{(SSR_{R} - SSR_{UR})}{SSR_{UR}} \frac{(T-k)}{q}
$$

Where $SSR_{R}$ is the sum of squared residuals of the restricted model and $SSR_{UR}$ is likewise for the unrestricted
model. $(T-k)$ is the degrees of freedom of the unrestricted model and $q$ is the number of restriction placed on the
restricted model.

<br>

This ratio is not distributed as a standard $F$ distribution under the null hypothesis. Instead one must use the
distribution tabluated by DF (which they do by Monte Carlo).


## $\phantom{Page 17}$ 

__Note:__ critical values from the DF distribution are much larger than for the standard $F$ distribution.

### The Augmented Dicky-Fuller Test

The original DF test implicitly makes the assumption of no serial correlation in $\varepsilon_{t}$. Often we would like
to allow for serial correlation in $\varepsilon_{t}$ and still test for a unit root. This can be done with the augmented
DF test (ADF Test).

<br>

This test is carried out by extending the data generating process (DGP) to include lagged changes in $y_{t}$ on the
right-hand side:


## $\phantom{Page 18}$

$$
y_{t} = \alpha + \beta t + \rho y_{t-1} + \sum\limits_{j=1}^{p} \lambda_{j} \Delta y_{t-j} + \varepsilon_{t}
$$

Where $\Delta y_{t} = y_{t} - y_{t-1}$.

<br>

The unit-root test proceeds as before:

1. Using OLS, run the unrestricted regression:

$$
\Delta y_{t} = \alpha + \beta t + (\rho - 1) y_{t-1} + \sum\limits_{j=1}^{p} \lambda_{j} \Delta y_{t-j} 
$$

2. Then the restricted regression

$$
\Delta y_{t} = \alpha + \sum\limits_{j=1}^{p} \lambda_{j} \Delta y_{t-j}  
$$

3. Form the $F$-ratio to test if the restrictions hold ($\beta = 0$ and $\rho = 1$).


## $\phantom{Page 19}$

There is another test due to Phillips and Perron that you may hear about, but which we will not cover in these notes.


## $\phantom{R Code}$

Please see the following blog post regarding R code for unit root tests: <https://www.r-bloggers.com/unit-root-tests/>
